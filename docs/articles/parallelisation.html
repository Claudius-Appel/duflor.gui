<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Parallelised computing as a method for increased performance • duflor.gui</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Parallelised computing as a method for increased performance">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">duflor.gui</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.0.4</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/general-user-manual.html">General user manual for 'duflor.gui'</a></li>
    <li><a class="dropdown-item" href="../articles/identifier-cropping.html">Restricting area for quantification of the identifier-dot</a></li>
    <li><a class="dropdown-item" href="../articles/image-cropping.html">Cropping the image for selective and faster analysis</a></li>
    <li><a class="dropdown-item" href="../articles/modifying-hsv-bounds.html">Fine-tuning HSV-boundaries</a></li>
    <li><a class="dropdown-item" href="../articles/optimising-speed.html">Measures to reduce execution time</a></li>
    <li><a class="dropdown-item" href="../articles/parallelisation.html">Parallelised computing as a method for increased performance</a></li>
    <li><a class="dropdown-item" href="../articles/raising-issues.html">How to report issues, raise suggestions and feedback</a></li>
    <li><a class="dropdown-item" href="../articles/saving-and-restoring-application-states.html">Saving and restoring application-states</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/Claudius-Appel/duflor.gui/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Parallelised computing as a method for increased performance</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/Claudius-Appel/duflor.gui/blob/HEAD/vignettes/parallelisation.Rmd" class="external-link"><code>vignettes/parallelisation.Rmd</code></a></small>
      <div class="d-none name"><code>parallelisation.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://Claudius-Appel.github.io/duflor.gui/">duflor.gui</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>Executing the analysis can takes varying amounts of time. There are 4
factors which influence the required time of analysis in a linearly
proportional manner:</p>
<ul>
<li>Number of checked pixels</li>
<li>Number of checked images</li>
<li>Number of spectra checked-for.</li>
<li>Image dimensions</li>
</ul>
<p>For each spectrum one wants to identify, every pixel must be checked
to fall within or outside the respectively defined HSV-boundaries.</p>
<p>It follows that in general, the following calculation yields the
total number of iterations required to calculate the results:</p>
<p><math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext mathvariant="normal">Iterations</mtext><mrow><mi>t</mi><mi>o</mi><mi>t</mi><mi>a</mi><mi>l</mi></mrow></msub><mo>=</mo><msub><mtext mathvariant="normal">Checked pixels</mtext><mtext mathvariant="normal">total</mtext></msub><mo>=</mo><msub><mi>N</mi><mrow><mi>I</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi><mi>s</mi></mrow></msub><mo>×</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mrow><mi>W</mi><mi>i</mi><mi>d</mi><mi>t</mi><mi>h</mi></mrow><mrow><mi>I</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi></mrow></msub><mo>×</mo><msub><mrow><mi>H</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi></mrow><mrow><mi>I</mi><mi>m</mi><mi>a</mi><mi>g</mi><mi>e</mi></mrow></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>×</mo><msub><mi>N</mi><mrow><mi>s</mi><mi>p</mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>r</mi><mi>a</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\text{Iterations}_{total} = \text{Checked pixels}_\text{total} = N_{Images}\times({Width}_{Image}\times{Height}_{Image})\times N_{spectra}</annotation></semantics></math></p>
<p>This step is not particularly complicated, nor is it particularly
resource-intensive. However,the sheer volume of iterations make this
operation rather slow.</p>
<p>Additionally, the process of <em>loading</em> an image into an
R-object to work on seems to be much more time-consuming than the
analysis described above itself. Unfortunately, this steps is cannot be
performed any faster currently. It is a bottle-neck that lies outside
the scope of the project.</p>
<div class="section level3">
<h3 id="the-general-steps">The general steps<a class="anchor" aria-label="anchor" href="#the-general-steps"></a>
</h3>
<p>The following steps <strong>must be performed</strong> to obtain the
results for a single image:</p>
<ol style="list-style-type: decimal">
<li>Load the image into an R-object</li>
<li>For each declared spectrum, check all pixels of the image against
the respective upper and lower bounds, and save the coordinates of
pixels fulfilling the condition</li>
<li>Insert the results into an object persistent across
spectrum-iterations</li>
<li>Convert all results into a results-object</li>
</ol>
<p>If multiple images are evaluated, the steps above must be performed
the corresponding number of times.</p>
</div>
<div class="section level3">
<h3 id="a-reasonable-worst-case-scenario">A reasonable worst-case scenario<a class="anchor" aria-label="anchor" href="#a-reasonable-worst-case-scenario"></a>
</h3>
<p>Let’s model a reasonable likely worst-case scenario:</p>
<ul>
<li>250 images</li>
<li>2 spectra</li>
<li>Image-width: 6000 pixels</li>
<li>Image-height: 4000 pixels</li>
</ul>
<p>To obtain all results, 250 images must be loaded. Without
parallelisation (i.e. in sequential execution mode), every subsequent
step requires its previous step to have concluded. Using the formula
above, a total of</p>
<p><span class="math display">$$
\text{Iterations}_{total} = \text{Checked pixels}_\text{total} =
N_{Images}\times({Width}_{Image}\times{Height}_{Image})\times
N_{spectra}\\
= 250\times(6000\times4000)\times2=1.2\times 10^{10}
$$</span></p>
<p>comparisons between a pixel’s HSV-triplet and a lower- and
upper-bound’s HSV-triplet must be performed. Note: the above calculation
is for a hypothetical root-area analysis of 250 images, where two
spectra must be quantified (roots and the identifier-area itself).</p>
<p>While a single such check is performed basically instantaneously, it
still takes <em>some</em> time.</p>
</div>
</div>
<div class="section level2">
<h2 id="how-a-parallelised-setup-can-help">How a parallelised setup can help<a class="anchor" aria-label="anchor" href="#how-a-parallelised-setup-can-help"></a>
</h2>
<p>R itself is a single-threaded language, and thus will utilise exactly
<em>one</em> thread of <em>one</em> CPU-core to perform the iterations
calculated above - by default.<br>
Thankfully, R has packages which allow the parallelised use of multiple
available CPU-cores to work on operations simultaneously.</p>
<p>Thus, this app allows the user to run the entire analysis-pipeline in
parallel, leveraging the <a href="https://github.com/RevolutionAnalytics/foreach" class="external-link">foreach</a>-package. It should be
stressed that the <em>entire</em> pipeline is parallelised,
<strong>including</strong> the loading-step.</p>
<div class="section level3">
<h3 id="advantages">Advantages<a class="anchor" aria-label="anchor" href="#advantages"></a>
</h3>
<p>Speed. By processing multiple images in parallel, the total time can
be (roughly) divided by the number of available workers.</p>
</div>
<div class="section level3">
<h3 id="limitations">Limitations<a class="anchor" aria-label="anchor" href="#limitations"></a>
</h3>
<ul>
<li>Setup-time: The process of setting up the parallel back-end takes a
certain amount of time<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;Typically on the scale of single-digit seconds&lt;/p&gt;"><sup>1</sup></a>
</li>
<li>RAM-usage: The amount of required RAM scales based on the number of
used workers, the size of the images which are analysed, and the
operating system.</li>
<li>Operating system: Without getting into the low-level details, there
is a significant difference between “Windows”-systems and
“Linux”/“MacOS” when it comes to managing back-ends for
parallel-computing. Apple- and Linux-machines have access to the
so-called <code>fork</code>-back-end. All three have access to the
<code>socket</code>-back-end.</li>
</ul>
<div class="section level4">
<h4 id="back-ends-socket-vs-fork">back-ends: <code>socket</code> vs <code>fork</code><a class="anchor" aria-label="anchor" href="#back-ends-socket-vs-fork"></a>
</h4>
<p>A so-called <strong><code>socket</code></strong>-back-end can be run
on Windows, MacOS and Linux.<br>
It works by separately exporting the required environment (variables,
functions, hidden objects, loaded packages, etc.) from the
master-process to every designated worker, which work secluded from each
other.<br>
When a worker finishes its workload, it must signal back to the
master-process that it has finished. Once all workers are done, their
results can be collected by the master, combined into a collective
output format, and used as a “normal” variable from there.</p>
<p>The major disadvantage is the significant overhead accumulating by
this back-and-forth, and thus a <code>socket</code>-cluster is
<strong>slow</strong> (compared to the <code>fork</code>-back-end
described below). For the reasons described above, a
<code>socket</code>-back-end also heavily increases RAM-usage (linearly
with the number of workers).</p>
<p>On the other hand, the <strong><code>fork</code></strong>-back-end
runs significantly faster.<br>
Instead of duplicating all data and providing a unique copy to each
worker-process, each worker gains access to the master’s environment. As
a consequence, the significant overhead of duplicating the environment
can be ignored, and workers instead just return their respective results
to the master process.<br>
Unfortunately, <strong>this back-end is not available on
windows</strong>. As an additional side note, machine-clusters cannot
use <code>fork</code>-back-ends.<br><br></p>
</div>
</div>
<div class="section level3">
<h3 id="suggestions">Suggestions<a class="anchor" aria-label="anchor" href="#suggestions"></a>
</h3>
<p>When setting up a parallel back-end via the app, you should consider
the specifications of your machine as described above:</p>
<ol style="list-style-type: decimal">
<li>You might be tempted to create a parallel back.end using all
available cores of a system. <strong>DO NOT DO SO.</strong> Simply
don’t. Assigning all available cores to your cluster will leave no core
freely-available for other programs on the machine to do their job. This
can and most certainly <strong>will</strong> cause havoc. Thus, leave at
least a single core available. When setting up parallelisation via the
shiny-GUI, it is not possible to use all cores available.</li>
<li>If you have a limited amount of available RAM, there comes a point
at which adding additional workers will deteriorate the performance of
the entire back-end. If your machine has e.g. 8 GB of available RAM, 2
workers might work efficiently, and 3 might work just as fast as a
sequential back-end<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content="&lt;p&gt;In fact, 3 might be as fast as a non-parallelised
back-end, or might even be slower. The same goes for adding even more
workers.&lt;/p&gt;"><sup>2</sup></a>. There is no clear guide to determine this
tipping-point. In general, if your cluster comes close to consuming all
available system RAM, adding more workers is likely to deteriorate
overall performance, and slightly reducing the number of workers might
even be beneficial.<br>
</li>
</ol>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Claudius Appel.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
